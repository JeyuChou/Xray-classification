{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Functional API ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh5ifMe0zuUp",
        "outputId": "59915c68-7cbe-475e-e1d5-4556967448fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 12054101256808518644, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 10850542912537822897\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 8440057814837351615\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14640891840\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 17228556216949611299\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHRyejYbSEWs",
        "outputId": "9dfd96ad-0b26-4be5-8847-3db6a20a08b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Conv2D,Dense,Flatten,Dropout,BatchNormalization,MaxPooling2D\n",
        "from keras.models import Model,load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from skimage import color\n",
        "import pickle\n",
        "from multiprocessing import Queue\n",
        "%load_ext google.colab.data_table\n",
        "import datetime\n",
        "skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=123)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The google.colab.data_table extension is already loaded. To reload it, use:\n",
            "  %reload_ext google.colab.data_table\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vmsJCMtW8IN",
        "outputId": "f6c00ea9-be12-47c8-e227-e0f3fc37e708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.3.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: wheel, google-pasta, numpy, gast, h5py, tensorboard, keras-preprocessing, termcolor, protobuf, opt-einsum, wrapt, six, scipy, grpcio, absl-py, astunparse, tensorflow-estimator\n",
            "Required-by: fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeDDI7-kTTa_",
        "outputId": "52af7887-15f7-40d3-accd-2e2391fd13c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/',force_remount=True)\n",
        "\n",
        "%cd 'drive/My Drive'\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6hw-Z3aT4pF"
      },
      "source": [
        "x_train = np.load('x_train.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "x_test = np.load('x_test.npy')\n",
        "y_test = np.load('y_test.npy')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSSaUvAyUqYs"
      },
      "source": [
        "for a in x_train:\n",
        "  print(max(a[56]),min(a[56]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4e2kx8kLKX1"
      },
      "source": [
        "num_neg = len(os.listdir('/content/drive/My Drive/X-ray/chest_xray/chest_xray/train/NORMAL'))\n",
        "num_pos = len(os.listdir('/content/drive/My Drive/X-ray/chest_xray/chest_xray/train/PNEUMONIA'))\n",
        "total_num = num_neg+num_pos"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh5iqxcnUHGM"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rotation_range=360,\n",
        "                             width_shift_range = 0.5,\n",
        "                             height_shift_range = 1.0,\n",
        "                             horizontal_flip = True,\n",
        "                             vertical_flip = True,\n",
        "                             rescale = 1./255.)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "no_batch = 64"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvayzNVnmBwt"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(128,128,1))\n",
        "#feature extract 1\n",
        "conv1 = Conv2D(16,kernel_size=3,activation='relu')(inputs)\n",
        "conv2 = Conv2D(16,kernel_size=5,activation='relu')(conv1)\n",
        "norm = BatchNormalization()(conv2)\n",
        "dropout = Dropout(0.25)\n",
        "conv3 = Conv2D(32,kernel_size=3,strides=2,activation='tanh')(norm)\n",
        "conv4 = Conv2D(64,kernel_size=3,activation='relu')(conv3)\n",
        "norm1 = BatchNormalization()(conv4)\n",
        "flatten = Flatten()(norm1)\n",
        "dense1 = Dense(64,activation='relu')(flatten)\n",
        "dense2 = Dense(128,activation='relu')(dense1)\n",
        "output = Dense(1,activation = 'sigmoid')(dense2)\n",
        "\n",
        "model = Model (inputs = inputs,outputs=output)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpfXhqjPLBXi"
      },
      "source": [
        "\n",
        "weight_for_0 = (1 / num_neg)*(total_num)/2.0 \n",
        "weight_for_1 = (1 / num_pos)*(total_num)/2.0\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PKtHhu-LhGU",
        "outputId": "4e6cdae6-6280-4912-fc29-edfd951ebd69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "model.compile(optimizer = 'adam',metrics = ['binary_accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()],loss = 'binary_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 128, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 126, 126, 16)      160       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 122, 122, 16)      6416      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 122, 122, 16)      64        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 60, 60, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 58, 58, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 58, 58, 64)        256       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 215296)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                13779008  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 13,817,489\n",
            "Trainable params: 13,817,329\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGl7jjx1zQ9h",
        "outputId": "bf3f8f63-fd20-4866-ecac-1ffdea278dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "recall = 'recall'\n",
        "total_list = list()\n",
        "fold = 0\n",
        "with tf.device('/device:GPU:0'):\n",
        "  for train,val in skf.split(x_train,y_train):\n",
        "    earlystopping = tf.keras.callbacks.EarlyStopping(monitor = recall,patience=5,verbose=1,restore_best_weights=True)\n",
        "    reduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor=recall,patience=2,verbose=1,cooldown=1)\n",
        "    print(fold)\n",
        "    model.fit(train_datagen.flow(x_train[train],y_train[train],\n",
        "              batch_size = no_batch),\n",
        "              epochs=25,\n",
        "              verbose=1,\n",
        "              callbacks=[earlystopping,reduceLR],\n",
        "              class_weight = class_weight)\n",
        "    scores = model.evaluate(val_datagen.flow(x_train[val],y_train[val]),return_dict=True)\n",
        "    fold += 1\n",
        "    print(scores)\n",
        "    total_list.append(scores)\n",
        "#final_eval\n",
        "print('--------------------------------------------/n')\n",
        "print('done training')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "Epoch 1/25\n",
            "74/74 [==============================] - 8s 103ms/step - loss: 2.7644 - binary_accuracy: 0.6842 - precision: 0.8557 - recall: 0.6909\n",
            "Epoch 2/25\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 2.0256 - binary_accuracy: 0.7186 - precision: 0.8764 - recall: 0.7227\n",
            "Epoch 3/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.5637 - binary_accuracy: 0.7062 - precision: 0.8804 - recall: 0.6992\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 1.5637 - binary_accuracy: 0.7062 - precision: 0.8804 - recall: 0.6992\n",
            "Epoch 4/25\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 0.9304 - binary_accuracy: 0.7424 - precision: 0.8995 - recall: 0.7350\n",
            "Epoch 5/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 0.6719 - binary_accuracy: 0.7710 - precision: 0.9174 - recall: 0.7599\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 0.6719 - binary_accuracy: 0.7710 - precision: 0.9174 - recall: 0.7599\n",
            "Epoch 6/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 0.6207 - binary_accuracy: 0.7821 - precision: 0.9158 - recall: 0.7779Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 8s 102ms/step - loss: 0.6207 - binary_accuracy: 0.7821 - precision: 0.9158 - recall: 0.7779\n",
            "Epoch 00006: early stopping\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2.2642 - binary_accuracy: 0.7424 - precision: 0.7424 - recall: 1.0000\n",
            "{'loss': 2.2641799449920654, 'binary_accuracy': 0.7423664331436157, 'precision': 0.7423664331436157, 'recall': 1.0}\n",
            "1\n",
            "Epoch 1/25\n",
            "74/74 [==============================] - 8s 102ms/step - loss: 1.3358 - binary_accuracy: 0.7313 - precision: 0.9135 - recall: 0.7046\n",
            "Epoch 2/25\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 1.0498 - binary_accuracy: 0.7619 - precision: 0.9153 - recall: 0.7484\n",
            "Epoch 3/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 0.9347 - binary_accuracy: 0.7725 - precision: 0.9153 - recall: 0.7642\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 0.9347 - binary_accuracy: 0.7725 - precision: 0.9153 - recall: 0.7642\n",
            "Epoch 4/25\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 0.8778 - binary_accuracy: 0.7799 - precision: 0.9241 - recall: 0.7665\n",
            "Epoch 5/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 0.8878 - binary_accuracy: 0.7759 - precision: 0.9186 - recall: 0.7659\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 0.8878 - binary_accuracy: 0.7759 - precision: 0.9186 - recall: 0.7659\n",
            "Epoch 6/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 0.8498 - binary_accuracy: 0.7827 - precision: 0.9215 - recall: 0.7730Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 8s 102ms/step - loss: 0.8498 - binary_accuracy: 0.7827 - precision: 0.9215 - recall: 0.7730\n",
            "Epoch 00006: early stopping\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 3.6541 - binary_accuracy: 0.7424 - precision: 0.7424 - recall: 1.0000\n",
            "{'loss': 3.654141902923584, 'binary_accuracy': 0.7423664331436157, 'precision': 0.7423664331436157, 'recall': 1.0}\n",
            "2\n",
            "Epoch 1/25\n",
            "74/74 [==============================] - 8s 104ms/step - loss: 1.1295 - binary_accuracy: 0.7594 - precision: 0.9058 - recall: 0.7542\n",
            "Epoch 2/25\n",
            "74/74 [==============================] - 8s 101ms/step - loss: 1.1608 - binary_accuracy: 0.7634 - precision: 0.9029 - recall: 0.7634\n",
            "Epoch 3/25\n",
            "74/74 [==============================] - 8s 102ms/step - loss: 1.1171 - binary_accuracy: 0.7590 - precision: 0.9117 - recall: 0.7476\n",
            "Epoch 4/25\n",
            "74/74 [==============================] - 7s 100ms/step - loss: 1.1551 - binary_accuracy: 0.7566 - precision: 0.9037 - recall: 0.7522\n",
            "Epoch 5/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.2218 - binary_accuracy: 0.7568 - precision: 0.9008 - recall: 0.7557\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.2218 - binary_accuracy: 0.7568 - precision: 0.9008 - recall: 0.7557\n",
            "Epoch 6/25\n",
            "74/74 [==============================] - 8s 102ms/step - loss: 1.1728 - binary_accuracy: 0.7543 - precision: 0.9065 - recall: 0.7459\n",
            "Epoch 7/25\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 1.2047 - binary_accuracy: 0.7611 - precision: 0.9039 - recall: 0.7588\n",
            "Epoch 8/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.0921 - binary_accuracy: 0.7602 - precision: 0.9125 - recall: 0.7488\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 1.0921 - binary_accuracy: 0.7602 - precision: 0.9125 - recall: 0.7488\n",
            "Epoch 9/25\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 1.1236 - binary_accuracy: 0.7622 - precision: 0.9139 - recall: 0.7502\n",
            "Epoch 10/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1439 - binary_accuracy: 0.7602 - precision: 0.9108 - recall: 0.7505\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
            "74/74 [==============================] - 7s 100ms/step - loss: 1.1439 - binary_accuracy: 0.7602 - precision: 0.9108 - recall: 0.7505\n",
            "Epoch 11/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1607 - binary_accuracy: 0.7636 - precision: 0.9029 - recall: 0.7637Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 1.1607 - binary_accuracy: 0.7636 - precision: 0.9029 - recall: 0.7637\n",
            "Epoch 00011: early stopping\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1.2658 - binary_accuracy: 0.7744 - precision: 0.7689 - recall: 0.9948\n",
            "{'loss': 1.2658382654190063, 'binary_accuracy': 0.7743785977363586, 'precision': 0.7689242959022522, 'recall': 0.9948453903198242}\n",
            "3\n",
            "Epoch 1/25\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 1.2119 - binary_accuracy: 0.7524 - precision: 0.9045 - recall: 0.7451\n",
            "Epoch 2/25\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.0826 - binary_accuracy: 0.7641 - precision: 0.9130 - recall: 0.7539\n",
            "Epoch 3/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1746 - binary_accuracy: 0.7607 - precision: 0.9049 - recall: 0.7571\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 1.1746 - binary_accuracy: 0.7607 - precision: 0.9049 - recall: 0.7571\n",
            "Epoch 4/25\n",
            "74/74 [==============================] - 7s 100ms/step - loss: 1.1660 - binary_accuracy: 0.7528 - precision: 0.9026 - recall: 0.7476\n",
            "Epoch 5/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1790 - binary_accuracy: 0.7605 - precision: 0.9099 - recall: 0.7516\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.1790 - binary_accuracy: 0.7605 - precision: 0.9099 - recall: 0.7516\n",
            "Epoch 6/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1018 - binary_accuracy: 0.7643 - precision: 0.9052 - recall: 0.7622Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 7s 100ms/step - loss: 1.1018 - binary_accuracy: 0.7643 - precision: 0.9052 - recall: 0.7622\n",
            "Epoch 00006: early stopping\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.6204 - binary_accuracy: 0.8413 - precision: 0.8522 - recall: 0.9510\n",
            "{'loss': 0.620391845703125, 'binary_accuracy': 0.8413001894950867, 'precision': 0.8521940112113953, 'recall': 0.9510309100151062}\n",
            "4\n",
            "Epoch 1/25\n",
            "74/74 [==============================] - 7s 100ms/step - loss: 1.1904 - binary_accuracy: 0.7583 - precision: 0.9048 - recall: 0.7536\n",
            "Epoch 2/25\n",
            "74/74 [==============================] - 7s 100ms/step - loss: 1.2275 - binary_accuracy: 0.7484 - precision: 0.9010 - recall: 0.7425\n",
            "Epoch 3/25\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.1209 - binary_accuracy: 0.7602 - precision: 0.9099 - recall: 0.7514\n",
            "Epoch 4/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1378 - binary_accuracy: 0.7579 - precision: 0.9062 - recall: 0.7516\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1378 - binary_accuracy: 0.7579 - precision: 0.9062 - recall: 0.7516\n",
            "Epoch 5/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1478 - binary_accuracy: 0.7613 - precision: 0.9045 - recall: 0.7585\n",
            "Epoch 6/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1059 - binary_accuracy: 0.7566 - precision: 0.9071 - recall: 0.7488\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.1059 - binary_accuracy: 0.7566 - precision: 0.9071 - recall: 0.7488\n",
            "Epoch 7/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1991 - binary_accuracy: 0.7535 - precision: 0.9049 - recall: 0.7462Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.1991 - binary_accuracy: 0.7535 - precision: 0.9049 - recall: 0.7462\n",
            "Epoch 00007: early stopping\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.6450 - binary_accuracy: 0.8375 - precision: 0.9391 - recall: 0.8351\n",
            "{'loss': 0.6449584364891052, 'binary_accuracy': 0.8374760746955872, 'precision': 0.939130425453186, 'recall': 0.8350515365600586}\n",
            "5\n",
            "Epoch 1/25\n",
            "74/74 [==============================] - 7s 100ms/step - loss: 1.0976 - binary_accuracy: 0.7660 - precision: 0.9068 - recall: 0.7631\n",
            "Epoch 2/25\n",
            "74/74 [==============================] - 7s 100ms/step - loss: 1.1002 - binary_accuracy: 0.7639 - precision: 0.9107 - recall: 0.7559\n",
            "Epoch 3/25\n",
            "74/74 [==============================] - 7s 101ms/step - loss: 1.1404 - binary_accuracy: 0.7568 - precision: 0.9066 - recall: 0.7496\n",
            "Epoch 4/25\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.1457 - binary_accuracy: 0.7551 - precision: 0.9035 - recall: 0.7502\n",
            "Epoch 5/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1148 - binary_accuracy: 0.7617 - precision: 0.9004 - recall: 0.7634\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.1148 - binary_accuracy: 0.7617 - precision: 0.9004 - recall: 0.7634\n",
            "Epoch 6/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1330 - binary_accuracy: 0.7598 - precision: 0.9048 - recall: 0.7559\n",
            "Epoch 7/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1691 - binary_accuracy: 0.7639 - precision: 0.9102 - recall: 0.7565\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.1691 - binary_accuracy: 0.7639 - precision: 0.9102 - recall: 0.7565\n",
            "Epoch 8/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1258 - binary_accuracy: 0.7558 - precision: 0.9098 - recall: 0.7448\n",
            "Epoch 9/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1626 - binary_accuracy: 0.7619 - precision: 0.9130 - recall: 0.7508\n",
            "Epoch 10/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1514 - binary_accuracy: 0.7626 - precision: 0.9055 - recall: 0.7594\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1514 - binary_accuracy: 0.7626 - precision: 0.9055 - recall: 0.7594\n",
            "Epoch 11/25\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.1661 - binary_accuracy: 0.7579 - precision: 0.9034 - recall: 0.7545\n",
            "Epoch 12/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1867 - binary_accuracy: 0.7522 - precision: 0.9042 - recall: 0.7451\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.1867 - binary_accuracy: 0.7522 - precision: 0.9042 - recall: 0.7451\n",
            "Epoch 13/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.0825 - binary_accuracy: 0.7696 - precision: 0.9101 - recall: 0.7651Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.0825 - binary_accuracy: 0.7696 - precision: 0.9101 - recall: 0.7651\n",
            "Epoch 00013: early stopping\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.0265 - binary_accuracy: 0.7533 - precision: 0.9360 - recall: 0.7165\n",
            "{'loss': 1.0264772176742554, 'binary_accuracy': 0.7533460855484009, 'precision': 0.936026930809021, 'recall': 0.7164948582649231}\n",
            "6\n",
            "Epoch 1/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1283 - binary_accuracy: 0.7685 - precision: 0.9142 - recall: 0.7594\n",
            "Epoch 2/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1227 - binary_accuracy: 0.7668 - precision: 0.9072 - recall: 0.7639\n",
            "Epoch 3/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1230 - binary_accuracy: 0.7675 - precision: 0.9129 - recall: 0.7591\n",
            "Epoch 4/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.2210 - binary_accuracy: 0.7600 - precision: 0.9023 - recall: 0.7588\n",
            "Epoch 5/25\n",
            "74/74 [==============================] - 7s 97ms/step - loss: 1.1148 - binary_accuracy: 0.7588 - precision: 0.9080 - recall: 0.7511\n",
            "Epoch 6/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1664 - binary_accuracy: 0.7622 - precision: 0.9071 - recall: 0.7571\n",
            "Epoch 7/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1339 - binary_accuracy: 0.7622 - precision: 0.9079 - recall: 0.7562\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
            "74/74 [==============================] - 7s 97ms/step - loss: 1.1339 - binary_accuracy: 0.7622 - precision: 0.9079 - recall: 0.7562\n",
            "Epoch 8/25\n",
            "74/74 [==============================] - 7s 97ms/step - loss: 1.1993 - binary_accuracy: 0.7653 - precision: 0.9078 - recall: 0.7611\n",
            "Epoch 9/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1985 - binary_accuracy: 0.7554 - precision: 0.9086 - recall: 0.7454\n",
            "Epoch 10/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.0508 - binary_accuracy: 0.7711 - precision: 0.9163 - recall: 0.7611\n",
            "Epoch 11/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1914 - binary_accuracy: 0.7541 - precision: 0.9042 - recall: 0.7479\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1914 - binary_accuracy: 0.7541 - precision: 0.9042 - recall: 0.7479\n",
            "Epoch 12/25\n",
            "74/74 [==============================] - 7s 97ms/step - loss: 1.1552 - binary_accuracy: 0.7647 - precision: 0.9137 - recall: 0.7542\n",
            "Epoch 13/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1585 - binary_accuracy: 0.7585 - precision: 0.9063 - recall: 0.7525\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
            "74/74 [==============================] - 7s 96ms/step - loss: 1.1585 - binary_accuracy: 0.7585 - precision: 0.9063 - recall: 0.7525\n",
            "Epoch 14/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1007 - binary_accuracy: 0.7666 - precision: 0.9086 - recall: 0.7622Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 7s 97ms/step - loss: 1.1007 - binary_accuracy: 0.7666 - precision: 0.9086 - recall: 0.7622\n",
            "Epoch 00014: early stopping\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.8260 - binary_accuracy: 0.7610 - precision: 0.9398 - recall: 0.7242\n",
            "{'loss': 0.8259832262992859, 'binary_accuracy': 0.7609942555427551, 'precision': 0.9397993087768555, 'recall': 0.7242268323898315}\n",
            "7\n",
            "Epoch 1/25\n",
            "74/74 [==============================] - 7s 98ms/step - loss: 1.1911 - binary_accuracy: 0.7537 - precision: 0.9058 - recall: 0.7456\n",
            "Epoch 2/25\n",
            "74/74 [==============================] - 7s 96ms/step - loss: 1.1955 - binary_accuracy: 0.7583 - precision: 0.9093 - recall: 0.7491\n",
            "Epoch 3/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1021 - binary_accuracy: 0.7662 - precision: 0.9125 - recall: 0.7577\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
            "74/74 [==============================] - 7s 96ms/step - loss: 1.1021 - binary_accuracy: 0.7662 - precision: 0.9125 - recall: 0.7577\n",
            "Epoch 4/25\n",
            "74/74 [==============================] - 7s 97ms/step - loss: 1.1581 - binary_accuracy: 0.7543 - precision: 0.9051 - recall: 0.7474\n",
            "Epoch 5/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1740 - binary_accuracy: 0.7583 - precision: 0.9046 - recall: 0.7539\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
            "74/74 [==============================] - 7s 96ms/step - loss: 1.1740 - binary_accuracy: 0.7583 - precision: 0.9046 - recall: 0.7539\n",
            "Epoch 6/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.2067 - binary_accuracy: 0.7554 - precision: 0.9033 - recall: 0.7508Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 7s 97ms/step - loss: 1.2067 - binary_accuracy: 0.7554 - precision: 0.9033 - recall: 0.7508\n",
            "Epoch 00006: early stopping\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 1.0235 - binary_accuracy: 0.7457 - precision: 0.9443 - recall: 0.6985\n",
            "{'loss': 1.0234566926956177, 'binary_accuracy': 0.7456979155540466, 'precision': 0.9442508816719055, 'recall': 0.6984536051750183}\n",
            "8\n",
            "Epoch 1/25\n",
            "74/74 [==============================] - 7s 96ms/step - loss: 1.1360 - binary_accuracy: 0.7590 - precision: 0.9052 - recall: 0.7542\n",
            "Epoch 2/25\n",
            "74/74 [==============================] - 7s 96ms/step - loss: 1.0980 - binary_accuracy: 0.7639 - precision: 0.9147 - recall: 0.7519\n",
            "Epoch 3/25\n",
            "74/74 [==============================] - 7s 95ms/step - loss: 1.1692 - binary_accuracy: 0.7573 - precision: 0.9041 - recall: 0.7528\n",
            "Epoch 4/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1535 - binary_accuracy: 0.7666 - precision: 0.9108 - recall: 0.7599\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
            "74/74 [==============================] - 7s 95ms/step - loss: 1.1535 - binary_accuracy: 0.7666 - precision: 0.9108 - recall: 0.7599\n",
            "Epoch 5/25\n",
            "74/74 [==============================] - 7s 94ms/step - loss: 1.1586 - binary_accuracy: 0.7647 - precision: 0.9111 - recall: 0.7568\n",
            "Epoch 6/25\n",
            "74/74 [==============================] - 7s 95ms/step - loss: 1.1224 - binary_accuracy: 0.7611 - precision: 0.9123 - recall: 0.7502\n",
            "Epoch 7/25\n",
            "74/74 [==============================] - 7s 95ms/step - loss: 1.1708 - binary_accuracy: 0.7562 - precision: 0.9048 - recall: 0.7505\n",
            "Epoch 8/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1602 - binary_accuracy: 0.7549 - precision: 0.9010 - recall: 0.7525\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
            "74/74 [==============================] - 7s 96ms/step - loss: 1.1602 - binary_accuracy: 0.7549 - precision: 0.9010 - recall: 0.7525\n",
            "Epoch 9/25\n",
            "74/74 [==============================] - 7s 96ms/step - loss: 1.1004 - binary_accuracy: 0.7662 - precision: 0.9099 - recall: 0.7602\n",
            "Epoch 10/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.0520 - binary_accuracy: 0.7670 - precision: 0.9134 - recall: 0.7579\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
            "74/74 [==============================] - 7s 95ms/step - loss: 1.0520 - binary_accuracy: 0.7670 - precision: 0.9134 - recall: 0.7579\n",
            "Epoch 11/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1263 - binary_accuracy: 0.7592 - precision: 0.9033 - recall: 0.7565Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 7s 96ms/step - loss: 1.1263 - binary_accuracy: 0.7592 - precision: 0.9033 - recall: 0.7565\n",
            "Epoch 00011: early stopping\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.9219 - binary_accuracy: 0.7782 - precision: 0.9564 - recall: 0.7345\n",
            "{'loss': 0.9219205975532532, 'binary_accuracy': 0.7782026529312134, 'precision': 0.9563758373260498, 'recall': 0.7345361113548279}\n",
            "9\n",
            "Epoch 1/25\n",
            "74/74 [==============================] - 7s 99ms/step - loss: 1.1380 - binary_accuracy: 0.7613 - precision: 0.9129 - recall: 0.7499\n",
            "Epoch 2/25\n",
            "74/74 [==============================] - 7s 97ms/step - loss: 1.0584 - binary_accuracy: 0.7696 - precision: 0.9093 - recall: 0.7659\n",
            "Epoch 3/25\n",
            "74/74 [==============================] - 7s 95ms/step - loss: 1.1678 - binary_accuracy: 0.7585 - precision: 0.9102 - recall: 0.7484\n",
            "Epoch 4/25\n",
            "74/74 [==============================] - 7s 93ms/step - loss: 1.1691 - binary_accuracy: 0.7549 - precision: 0.9023 - recall: 0.7510\n",
            "Epoch 5/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1494 - binary_accuracy: 0.7628 - precision: 0.9049 - recall: 0.7602\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.000000142800998e-27.\n",
            "74/74 [==============================] - 7s 93ms/step - loss: 1.1494 - binary_accuracy: 0.7628 - precision: 0.9049 - recall: 0.7602\n",
            "Epoch 6/25\n",
            "74/74 [==============================] - 7s 94ms/step - loss: 1.1185 - binary_accuracy: 0.7607 - precision: 0.9085 - recall: 0.7533\n",
            "Epoch 7/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1858 - binary_accuracy: 0.7562 - precision: 0.9048 - recall: 0.7504\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000001235416984e-28.\n",
            "74/74 [==============================] - 7s 95ms/step - loss: 1.1858 - binary_accuracy: 0.7562 - precision: 0.9048 - recall: 0.7504\n",
            "Epoch 8/25\n",
            "74/74 [==============================] - ETA: 0s - loss: 1.1561 - binary_accuracy: 0.7602 - precision: 0.9065 - recall: 0.7547Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 7s 96ms/step - loss: 1.1561 - binary_accuracy: 0.7602 - precision: 0.9065 - recall: 0.7547\n",
            "Epoch 00008: early stopping\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.9353 - binary_accuracy: 0.7342 - precision: 0.9433 - recall: 0.6838\n",
            "{'loss': 0.9352588057518005, 'binary_accuracy': 0.7342256307601929, 'precision': 0.9432623982429504, 'recall': 0.6838046312332153}\n",
            "--------------------------------------------/n\n",
            "done training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gyfy4lxIKEU"
      },
      "source": [
        "xray_model = model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQjdhR1hu1mo"
      },
      "source": [
        "xray_model = load_model('xray_model.h5')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxDZLmk1Okag"
      },
      "source": [
        "x_ray_url= 'https://www.radiologymasterclass.co.uk/images/quizzes/Quiz-Images-Chest-1/question_1.jpg'\n",
        "path = tf.keras.utils.get_file('xray',x_ray_url)\n",
        "\n",
        "img = keras.preprocessing.image.load_img(path,color_mode='grayscale',target_size=(128,128))\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = img_array/255.\n",
        "expanded = tf.expand_dims(img_array,0)\n",
        "\n",
        "prediction = xray_model.predict(expanded)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gcFgSfSrskW"
      },
      "source": [
        "score=tf.math.sigmoid(prediction)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLwqqv1CvQif"
      },
      "source": [
        "classes = ['NORMAL', 'PNEUMONIA']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2bfTKk2sKps",
        "outputId": "331f42ee-8b18-4d61-89c0-1b82f93d9e39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f\"this image most likely belongs to {classes[np.argmax(score)]} lung with a {np.max(score)*100} percent confidence\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this image most likely belongs to NORMAL lung with a 50.000590085983276 percent confidence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASRMp7rNvA-M"
      },
      "source": [
        "model.save('xray_model.h5')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5nmUbiKvqH1",
        "outputId": "23db403e-d0eb-4f18-b3e9-dec40f7cd6c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "!pip install lime"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/86/91a13127d83d793ecb50eb75e716f76e6eda809b6803c5a4ff462339789e/lime-0.2.0.1.tar.gz (275kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 26.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 17.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 15.2MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 9.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 235kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (0.17.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.5)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (7.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-cp36-none-any.whl size=283845 sha256=e627441eaa9e262a6e74835f6011f3c13b59846b46bbf2de10595874135da1f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/4f/a5/0bc765457bd41378bf3ce8d17d7495369d6e7ca3b712c60c89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1qgbMZMxBkl"
      },
      "source": [
        "from lime import lime_image"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PelPh3nAxmK1"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdqye1Fcxchh"
      },
      "source": [
        "explainer = lime_image.LimeImageExplainer()\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCIPYOZlxnF2"
      },
      "source": [
        "rgb_img = tf.image.grayscale_to_rgb(expanded)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nmm3fsTycLI",
        "outputId": "2621079f-d1e0-4779-b21d-79001596c73d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rgb_img.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 128, 128, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHVi4cPa0Xm1"
      },
      "source": [
        "array_rgb =rgb_img.numpy()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTGlVJEQ0d-s"
      },
      "source": [
        "transformed_img=np.reshape(array_rgb,(128,128,3))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByhZ1dX42Gb-",
        "outputId": "ca62b156-6850-454c-8533-9a1d434f6b2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "transformed_img.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TC4V34ZIk_7"
      },
      "source": [
        "\n",
        "def grey_model (rgb_img,model):\n",
        "  grey_img = color.rgb2gray(rgb_img)\n",
        "  return model.predict(grey_img)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmUeJdOwyct0",
        "outputId": "aa710f48-003d-497f-b074-a66309234445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        }
      },
      "source": [
        "explanation=explainer.explain_instance(transformed_img,grey_model(transformed_img,xray_model),labels=2,hide_color=0,top_labels=2,num_samples=16384)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 128, 128, 1) for input Tensor(\"input_1:0\", shape=(None, 128, 128, 1), dtype=float32), but it was called on an input with incompatible shape (32, 128).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-b8b7980ea13f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexplanation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrey_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxray_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhide_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16384\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-889e72ff6638>\u001b[0m in \u001b[0;36mgrey_model\u001b[0;34m(rgb_img, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrey_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrgb_img\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mgrey_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrey_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3142\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1462 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1452 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1445 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1418 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:196 assert_input_compatibility\n        str(x.shape.as_list()))\n\n    ValueError: Input 0 of layer conv2d is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: [32, 128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzxA9PFpW_oP",
        "outputId": "39ee8cab-decf-4257-934c-f692727c32ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "xray_model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 128, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 126, 126, 16)      160       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 122, 122, 16)      6416      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 122, 122, 16)      64        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 60, 60, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 58, 58, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 58, 58, 64)        256       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 215296)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                13779008  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 13,817,489\n",
            "Trainable params: 13,817,329\n",
            "Non-trainable params: 160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYWcgLdzzEXh",
        "outputId": "0ae6e2c3-304b-431d-d729-3c2315f3e841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "tf.keras.models.save_model(xray_model,filepath = 'xray_model',save_format='tf')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-b1917a67cd1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxray_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'xray_model'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    132\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[0;32m--> 134\u001b[0;31m                           signatures, options)\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# we use the default replica context here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m       \u001b[0msave_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m    979\u001b[0m   \u001b[0;31m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m   \u001b[0;31m# the SavedModel proto itself.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m   \u001b[0mutils_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_variables_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m   ckpt_options = checkpoint_options.CheckpointOptions(\n\u001b[1;32m    983\u001b[0m       experimental_io_device=options.experimental_io_device)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/utils_impl.py\u001b[0m in \u001b[0;36mget_or_create_variables_dir\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    212\u001b[0m   \u001b[0mvariables_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_variables_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvariables_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir\u001b[0;34m(dirname)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m   \"\"\"\n\u001b[0;32m--> 465\u001b[0;31m   \u001b[0mrecursive_create_dir_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mrecursive_create_dir_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m   \"\"\"\n\u001b[0;32m--> 480\u001b[0;31m   \u001b[0m_pywrap_file_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecursivelyCreateDir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: xray_model is not a directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP_DKLriTwbg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}